name: ML CI Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-test-train:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout repository
      - name: Checkout code
        uses: actions/checkout@v4

      # Step 2: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      # Step 3: Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Step 4: Run code quality checks
      - name: Run Ruff
        run: ruff check src tests

      - name: Run Flake8
        run: flake8 src tests

      - name: Run Black check
        run: black --check src tests

      # Step 5: Run tests
      - name: Run Pytest
        run: pytest --maxfail=1 --disable-warnings -q

      # Step 6: Run data validation, training, and evaluation
      - name: Run data validation, training, and evaluation
        run: |
          python - <<'EOF'
          import pandas as pd
          from src.data_validation import validate_dataframe
          from src.train import train_model
          from src.evaluate import evaluate_model
          import json
          import joblib
          import os

          df = pd.DataFrame({
              "feature1": [1, 2, 3, 4, 5],
              "feature2": [10, 20, 30, 40, 50],
              "target": [0, 1, 0, 1, 0],
          })

          if not validate_dataframe(df):
              raise ValueError("Data validation failed")

          model, (X_val, y_val), model_path = train_model(df)
          metrics = evaluate_model(model, X_val, y_val)
          print("Model metrics:", metrics)

          if metrics["accuracy"] < 0.5:
              raise ValueError("Model accuracy below threshold")

          with open("reports/performance_report.json", "r") as f:
              report = json.load(f)
              print("Performance report:", report)
          EOF

      # Step 7: Upload model and report artifacts
      - name: Upload artifacts
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: model-and-report
          path: |
            models/
            reports/performance_report.json

      # Step 8: Create GitHub Release if model passes
      - name: Create GitHub Release
        if: success()
        uses: softprops/action-gh-release@v2
        with:
          tag_name: v${{ github.run_number }}
          name: "Model Release v${{ github.run_number }}"
          body: "Automated release with trained model and performance report."
          files: |
            models/*.joblib
            reports/performance_report.json
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
